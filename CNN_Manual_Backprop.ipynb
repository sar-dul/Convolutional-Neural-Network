{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CDAR4piBAyd0",
        "18lVOUi9A4P4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1778,
      "metadata": {
        "id": "jeX7MGMbiOyW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Download and Load Data"
      ],
      "metadata": {
        "id": "u7ku7sjVyLdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((10, 10)),  # Resize images\n",
        "    transforms.ToTensor(),          # Convert to Tensor\n",
        "])\n",
        "\n",
        "# Download and load the training dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Download and load the test dataset\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "print(\"Datasets downloaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9BpYROdi8QV",
        "outputId": "957f18b3-25b9-46cb-fe46-88ff0346aaa5",
        "collapsed": true
      },
      "execution_count": 1779,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Test and Validation Split"
      ],
      "metadata": {
        "id": "9XxdB_XyyTWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = torch.stack([train_dataset[i][0] for i in range(3)])\n",
        "\n",
        "# test_images = train_dataset[0][0].unsqueeze(0)"
      ],
      "metadata": {
        "id": "55SoY5Eppgtb"
      },
      "execution_count": 1780,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86oZfaLfztBG",
        "outputId": "c669146c-9599-48af-944d-c8baa4b8bedd"
      },
      "execution_count": 1781,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 1781
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_wwa4EQIXBf",
        "outputId": "36ba09a9-319c-4de8-b573-ce45ef87466e"
      },
      "execution_count": 1782,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the first 5 images and their labels from the training dataset\n",
        "x_train = train_dataset.data[:5].unsqueeze(1).float() / 255  # Normalize and add channel dimension\n",
        "y_train = train_dataset.targets[:5]\n",
        "\n",
        "# Extract the first 5 images and their labels from the test dataset\n",
        "x_test = test_dataset.data[:5].unsqueeze(1).float() / 255  # Normalize and add channel dimension\n",
        "y_test = test_dataset.targets[:5]"
      ],
      "metadata": {
        "id": "S4n8H84ti9xx"
      },
      "execution_count": 1783,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aK79ezzjACW",
        "outputId": "78da3e04-5944-4ecf-bb24-c578c3a8e12e"
      },
      "execution_count": 1784,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 1, 28, 28]),\n",
              " torch.Size([5]),\n",
              " torch.Size([5, 1, 28, 28]),\n",
              " torch.Size([5]))"
            ]
          },
          "metadata": {},
          "execution_count": 1784
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network"
      ],
      "metadata": {
        "id": "pLHtmP4iQKL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return torch.where(x < 0, 0, x)\n",
        "\n",
        "def xavier_uniform(n_in, n_out):\n",
        "  limit = torch.sqrt(torch.tensor(6.0) / (n_in + n_out))\n",
        "  return torch.empty(n_in, n_out).uniform_(-limit, limit)"
      ],
      "metadata": {
        "id": "mWKT2JOxymdC"
      },
      "execution_count": 1785,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_padding(tensor, pad=1):\n",
        "    # Get the shape of the original tensor\n",
        "    original_batch, _, original_height, original_width = tensor.shape\n",
        "\n",
        "    # Create a new tensor filled with zeros (padding value)\n",
        "    padded_tensor = torch.zeros((original_batch, 1, original_height + 2 * pad, original_width + 2 * pad), dtype=tensor.dtype)\n",
        "\n",
        "    # Place the original tensor in the center of the padded tensor\n",
        "    padded_tensor[:, :, pad:pad + original_height, pad:pad + original_width] = tensor\n",
        "\n",
        "    return padded_tensor\n",
        "\n",
        "def rotate_180(tensor):\n",
        "    return torch.flip(tensor, dims=[2, 3])"
      ],
      "metadata": {
        "id": "mfWPJvZI9Dtp"
      },
      "execution_count": 1786,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution"
      ],
      "metadata": {
        "id": "CDAR4piBAyd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(a, kernel, stride=1, padding=0):\n",
        "\n",
        "    a = apply_padding(a, pad=padding)\n",
        "\n",
        "    batch, channels, rows, cols = a.shape\n",
        "    ker_batch, ker_channels, ker_rows, ker_cols = kernel.shape\n",
        "\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_rows = (rows - ker_rows) // stride + 1\n",
        "    output_cols = (cols - ker_cols) // stride + 1\n",
        "\n",
        "    # Initialize an output tensor\n",
        "    result = torch.zeros((batch, ker_batch, output_rows, output_cols), dtype=torch.float32)\n",
        "\n",
        "    # Perform the convolution operation\n",
        "    for b in range(batch):  # Iterate over the batch\n",
        "        for k in range(ker_batch):  # Iterate over the output channels\n",
        "            for i in range(output_rows):  # Iterate over the rows of the output\n",
        "                for j in range(output_cols):  # Iterate over the columns of the output\n",
        "                    row_start = i * stride\n",
        "                    col_start = j * stride\n",
        "                    sub_matrix = a[b, :, row_start:row_start + ker_rows, col_start:col_start + ker_cols]\n",
        "\n",
        "                    # element-wise multiplication and summation\n",
        "                    cov_op = (sub_matrix * kernel[k, :, :, :]).sum()\n",
        "                    result[b, k, i, j] = cov_op\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "gfJW8N7fQmAF"
      },
      "execution_count": 1787,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_back(a, kernel, stride=1, padding=0):\n",
        "\n",
        "    a = apply_padding(a, pad=padding)\n",
        "\n",
        "    batch, channels, rows, cols = a.shape\n",
        "    ker_batch, ker_channels, ker_rows, ker_cols = kernel.shape\n",
        "\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_rows = (rows - ker_rows) // stride + 1\n",
        "    output_cols = (cols - ker_cols) // stride + 1\n",
        "    output_batch = (batch - ker_batch) // stride + 1\n",
        "\n",
        "    # Initialize an output tensor\n",
        "    result = torch.zeros((output_batch, ker_channels, output_rows, output_cols), dtype=torch.float32)\n",
        "\n",
        "    # Perform the convolution operation\n",
        "\n",
        "    for k in range(ker_batch):  # Iterate over the output channels\n",
        "        for i in range(output_rows):  # Iterate over the rows of the output\n",
        "            for j in range(output_cols):  # Iterate over the columns of the output\n",
        "                cov_op = 0\n",
        "                for b in range(batch):  # Iterate over the batch\n",
        "\n",
        "                  row_start = i * stride\n",
        "                  col_start = j * stride\n",
        "                  sub_matrix = a[b, :, row_start:row_start + ker_rows, col_start:col_start + ker_cols]\n",
        "\n",
        "                  # element-wise multiplication and summation\n",
        "                  cov_op += (sub_matrix * kernel[b, :, :, :]).sum()\n",
        "                  result[0, 0, i, j] = cov_op\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "41DgwnX01LH3"
      },
      "execution_count": 1788,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Convolution"
      ],
      "metadata": {
        "id": "18lVOUi9A4P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn([2, 1, 6, 6])\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5FV3IDwV2Ew",
        "outputId": "f2545a18-b1c6-4bc7-be91-0d40e780823e"
      },
      "execution_count": 1789,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 1789
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = torch.randn([2, 1, 4, 4])\n",
        "kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obAwgPTuV3G-",
        "outputId": "89269dea-90cb-45cc-e62f-2cd5fef9b44d"
      },
      "execution_count": 1790,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1682, -0.8352,  0.1929,  0.5968],\n",
              "          [-0.0347,  0.4319, -0.6917, -1.0690],\n",
              "          [-0.0359, -0.2369,  1.4733, -0.0764],\n",
              "          [-0.2969,  0.0152,  0.3667,  0.7715]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1833, -1.6825,  1.8818, -1.6269],\n",
              "          [ 1.2929, -1.3502, -1.0637, -0.6175],\n",
              "          [ 0.0070,  1.5967, -0.6280,  1.0502],\n",
              "          [-0.3086,  0.8544,  2.1633,  0.4656]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 1790
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform convolution using PyTorch\n",
        "\n",
        "a_tor = a.clone()\n",
        "kernel_tor = kernel.clone()\n",
        "\n",
        "pytorch_conv = F.conv2d(a_tor, kernel_tor, stride=1)\n",
        "print(pytorch_conv .shape)\n",
        "print(pytorch_conv[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU0cZJXCbXR2",
        "outputId": "c1f93a2e-1ce5-4453-cbac-68c4ba5f100f"
      },
      "execution_count": 1791,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3, 3])\n",
            "tensor([[-2.2798, -1.6293,  0.7451],\n",
            "        [ 3.4613, -3.1083, -3.0839],\n",
            "        [ 3.8613,  2.4461,  1.0630]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform convolution\n",
        "result = conv(a, kernel, stride=1)\n",
        "print(result.shape)\n",
        "print(result[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsEaCTESWyl",
        "outputId": "b6e55391-871c-481a-fde6-e546082fb2b4"
      },
      "execution_count": 1792,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3, 3])\n",
            "tensor([[-2.2798, -1.6293,  0.7451],\n",
            "        [ 3.4613, -3.1083, -3.0839],\n",
            "        [ 3.8613,  2.4461,  1.0630]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max Pooling"
      ],
      "metadata": {
        "id": "mYRhYiqCA6E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_pool(a, kernel, stride = kernel):\n",
        "\n",
        "    batch, channels, rows, cols = a.shape\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_rows = (rows - kernel) // stride + 1\n",
        "    output_cols = (cols - kernel) // stride + 1\n",
        "\n",
        "    # Initialize an output tensor\n",
        "    result = torch.zeros((batch, 1, output_rows, output_cols))\n",
        "\n",
        "    # Perform the convolution operation\n",
        "    for b in range(batch):\n",
        "      for i in range(output_rows):\n",
        "          for j in range(output_cols):\n",
        "              row_start = i * stride\n",
        "              col_start = j * stride\n",
        "              sub_matrix = a[b, :,row_start:row_start+kernel, col_start:col_start+kernel]\n",
        "              pool_op = sub_matrix.max()\n",
        "              result[b, 0, i, j] = pool_op\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "YeqnOWtfcaut"
      },
      "execution_count": 1793,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pool_back(a, kernel, grad,  stride = kernel):\n",
        "\n",
        "    batch, channels, rows, cols = a.shape\n",
        "\n",
        "    # Calculate the output dimensions\n",
        "    output_rows = (rows - kernel) // stride + 1\n",
        "    output_cols = (cols - kernel) // stride + 1\n",
        "\n",
        "    # Initialize an output tensor\n",
        "    # result_identity = torch.zeros((batch, 1, rows, cols))\n",
        "    result_gradient = torch.zeros((batch, 1, rows, cols))\n",
        "\n",
        "    # Create an iterator by flattening the tensor\n",
        "    grad_iterator = iter(grad.flatten())\n",
        "\n",
        "\n",
        "    # Perform the convolution operation\n",
        "    for b in range(batch):\n",
        "      for i in range(output_rows):\n",
        "          for j in range(output_cols):\n",
        "\n",
        "              row_start = i * stride\n",
        "              col_start = j * stride\n",
        "              sub_matrix = a[b, :,row_start:row_start+kernel, col_start:col_start+kernel]\n",
        "              # max_ele = sub_matrix.max()\n",
        "              # Find the maximum value in the tensor\n",
        "              max_ele = torch.max(sub_matrix)\n",
        "              num_max_ele = (sub_matrix == max_ele).sum().item()\n",
        "\n",
        "              _, sub_rows, sub_cols = sub_matrix.shape\n",
        "\n",
        "              # Get the next element\n",
        "              next_element = next(grad_iterator)\n",
        "\n",
        "              for k in range(sub_rows):\n",
        "                  for l in range(sub_cols):\n",
        "                      if sub_matrix[0, k, l] == max_ele:\n",
        "                          pool_op = (1 / num_max_ele)\n",
        "                      else:\n",
        "                          pool_op = 0\n",
        "\n",
        "                      # result_identity[b, 0, row_start + k, col_start + l] = pool_op\n",
        "                      result_gradient[b, 0, row_start + k, col_start + l] = pool_op * next_element\n",
        "\n",
        "                      batch, channels, rows, cols = a.shape\n",
        "\n",
        "    return result_gradient\n"
      ],
      "metadata": {
        "id": "eVnQ_mOLo4Up"
      },
      "execution_count": 1794,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Max Pooling"
      ],
      "metadata": {
        "id": "JhNfTrwcA7w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = test_images\n",
        "b[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9716b718-c3bd-4682-86fb-bcd170ae2ac6",
        "id": "bE4P3TgL8WkN"
      },
      "execution_count": 1795,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0157, 0.0510, 0.1020, 0.1529, 0.1922, 0.0980,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.1176, 0.5216, 0.7059, 0.7647, 0.6000, 0.4431, 0.1686,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0784, 0.4471, 0.7490, 0.3098, 0.1765, 0.0157, 0.0039,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0353, 0.4784, 0.3333, 0.0510, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.5294, 0.5333, 0.0745, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0078, 0.1098, 0.4431, 0.8000, 0.1843, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0118, 0.1059, 0.3647, 0.7216, 0.6902, 0.3294, 0.0353, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.1961, 0.6118, 0.6706, 0.4000, 0.0784, 0.0039, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0431, 0.0941, 0.0549, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 1795
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = 2"
      ],
      "metadata": {
        "id": "YBfxnhHn8WkN"
      },
      "execution_count": 1796,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform convolution using PyTorch\n",
        "\n",
        "b_tor = b.clone()\n",
        "\n",
        "pytorch_pool = F.max_pool2d(b_tor, kernel_size=kernel, stride=2)\n",
        "print(pytorch_pool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4fb140-557b-4c65-a545-ac73090395c7",
        "id": "hm7jEV3Z8WkN"
      },
      "execution_count": 1797,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0000, 0.0157, 0.1020, 0.1922, 0.0980],\n",
            "          [0.0000, 0.5216, 0.7647, 0.6000, 0.1686],\n",
            "          [0.0000, 0.0353, 0.5294, 0.5333, 0.0000],\n",
            "          [0.0118, 0.3647, 0.7216, 0.8000, 0.0000],\n",
            "          [0.1961, 0.6706, 0.4000, 0.0039, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.2784, 0.4235, 0.0000],\n",
            "          [0.0000, 0.3098, 0.8549, 0.8000, 0.0784],\n",
            "          [0.0118, 0.6314, 0.2824, 0.6980, 0.1961],\n",
            "          [0.0196, 0.6667, 0.5882, 0.4863, 0.0157],\n",
            "          [0.0039, 0.5137, 0.4078, 0.0039, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0078, 0.0039, 0.0000, 0.0941, 0.0196],\n",
            "          [0.4392, 0.1412, 0.0000, 0.5059, 0.0667],\n",
            "          [0.5529, 0.4824, 0.4510, 0.6392, 0.0039],\n",
            "          [0.0549, 0.1059, 0.0588, 0.5725, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0431, 0.4980, 0.0000]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform pooling\n",
        "result = max_pool(b, kernel, stride=2)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b61c284-8abd-43f4-9d64-aaf8ec30c8a7",
        "id": "oRQLKeta8WkN"
      },
      "execution_count": 1798,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0000, 0.0157, 0.1020, 0.1922, 0.0980],\n",
            "          [0.0000, 0.5216, 0.7647, 0.6000, 0.1686],\n",
            "          [0.0000, 0.0353, 0.5294, 0.5333, 0.0000],\n",
            "          [0.0118, 0.3647, 0.7216, 0.8000, 0.0000],\n",
            "          [0.1961, 0.6706, 0.4000, 0.0039, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.2784, 0.4235, 0.0000],\n",
            "          [0.0000, 0.3098, 0.8549, 0.8000, 0.0784],\n",
            "          [0.0118, 0.6314, 0.2824, 0.6980, 0.1961],\n",
            "          [0.0196, 0.6667, 0.5882, 0.4863, 0.0157],\n",
            "          [0.0039, 0.5137, 0.4078, 0.0039, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0078, 0.0039, 0.0000, 0.0941, 0.0196],\n",
            "          [0.4392, 0.1412, 0.0000, 0.5059, 0.0667],\n",
            "          [0.5529, 0.4824, 0.4510, 0.6392, 0.0039],\n",
            "          [0.0549, 0.1059, 0.0588, 0.5725, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0431, 0.4980, 0.0000]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data and Weights Initialization"
      ],
      "metadata": {
        "id": "Q7hIK14VB7FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nhidden = 64\n",
        "nhidden2 = 32\n",
        "noutput = 10"
      ],
      "metadata": {
        "id": "vbN4wGGyCvO3"
      },
      "execution_count": 1799,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPvQvz37BaXX",
        "outputId": "0607b79c-4c8c-461e-a4e3-c4d75497c669"
      },
      "execution_count": 1800,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 1, 28, 28]), torch.Size([5]))"
            ]
          },
          "metadata": {},
          "execution_count": 1800
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filter1 = torch.randn(1, 1, 3, 3) * 0.01\n",
        "filter1 = filter1.requires_grad_(True)\n",
        "filter2 = torch.randn(1, 1, 3, 3) * 0.01\n",
        "filter2 = filter2.requires_grad_(True)\n",
        "pool_kernel = 2\n",
        "\n",
        "w1 = torch.randn(25, nhidden, requires_grad=True) * 0.01\n",
        "b1 = torch.randn(1, nhidden, requires_grad=True) * 0.01\n",
        "\n",
        "w2 = torch.randn(nhidden, nhidden2, requires_grad=True) * 0.01\n",
        "b2 = torch.randn(1, nhidden2, requires_grad=True) * 0.01\n",
        "\n",
        "w3 = torch.randn(nhidden2, noutput, requires_grad=True) * 0.01\n",
        "b3 = torch.randn(1, noutput, requires_grad=True) * 0.01"
      ],
      "metadata": {
        "id": "YQaPvqusB9te"
      },
      "execution_count": 1801,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Pass (Manual)"
      ],
      "metadata": {
        "id": "Z4BsyidTBagN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolution layers\n",
        "conv1 = conv(x_train, filter1, stride=1)\n",
        "print(conv1.shape)\n",
        "pool1 = max_pool(conv1, pool_kernel, stride=2)\n",
        "print(pool1.shape)\n",
        "conv2 = conv(pool1, filter2, stride=1)\n",
        "print(conv2.shape)\n",
        "pool2 = max_pool(conv2, pool_kernel, stride=2)\n",
        "print(pool2.shape)\n",
        "flatten = torch.flatten(pool2,start_dim=1)\n",
        "print(flatten.shape)\n",
        "\n",
        "# Fully connected layers\n",
        "z1 = flatten @ w1 + b1\n",
        "af1 = relu(z1)\n",
        "z2 = af1 @ w2 + b2\n",
        "af2 = relu(z2)\n",
        "z3 = af2 @ w3 + b3\n",
        "\n",
        "# Softmax and Loss\n",
        "z_max = z3.max(1, keepdim=True).values\n",
        "norm_z = z3 - z_max\n",
        "exp_norm_z = torch.exp(norm_z)\n",
        "z_sum = exp_norm_z.sum(dim=1, keepdims=True)\n",
        "z_sum_inv = z_sum**-1\n",
        "probs = exp_norm_z * z_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(len(x_train)), y_train].mean()"
      ],
      "metadata": {
        "id": "7qqE_jNxBUqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c50df56-f646-45a7-cb05-43954311ff81"
      },
      "execution_count": 1802,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 26, 26])\n",
            "torch.Size([5, 1, 13, 13])\n",
            "torch.Size([5, 1, 11, 11])\n",
            "torch.Size([5, 1, 5, 5])\n",
            "torch.Size([5, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter1.retain_grad()\n",
        "conv1.retain_grad()\n",
        "pool1.retain_grad()\n",
        "filter2.retain_grad()\n",
        "conv2.retain_grad()\n",
        "pool2.retain_grad()\n",
        "flatten.retain_grad()\n",
        "z1.retain_grad()\n",
        "af1.retain_grad()\n",
        "z2.retain_grad()\n",
        "af2.retain_grad()\n",
        "z3.retain_grad()\n",
        "z_max.retain_grad()\n",
        "norm_z.retain_grad()\n",
        "exp_norm_z.retain_grad()\n",
        "z_sum.retain_grad()\n",
        "z_sum_inv.retain_grad()\n",
        "probs.retain_grad()\n",
        "logprobs.retain_grad()\n",
        "\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "Ln3KTp70oxSn"
      },
      "execution_count": 1803,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward Atomic Softmax\n",
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(len(x_train)), y_train] = -1.0 / len(x_train)\n",
        "dprobs = (1.0 / probs) * dlogprobs\n",
        "dz_sum_inv = (exp_norm_z * dprobs).sum(dim=1, keepdim=True)\n",
        "dexp_norm_z = z_sum_inv * dprobs\n",
        "dz_sum = (-z_sum**-2) * dz_sum_inv\n",
        "dexp_norm_z += torch.ones_like(exp_norm_z) * dz_sum\n",
        "dnorm_z = exp_norm_z * dexp_norm_z\n",
        "dz_max = (-dnorm_z).sum(dim=1, keepdim=True)\n",
        "dz3 = dnorm_z.clone()\n",
        "dz_max = (-dnorm_z).sum(dim=1, keepdim=True)\n",
        "dz3+=torch.nn.functional.one_hot(z3.max(1).indices,num_classes=z3.shape[1])*dz_max\n",
        "\n",
        "# Backward Atomic Fully Connected Layer\n",
        "dw3 = af2.T @ dz3\n",
        "db3 = dz3.sum(0)\n",
        "daf2 = dz3 @ w3.T\n",
        "dz2 = z2.clone()\n",
        "dz2 = torch.where(dz2 > 0, 1, 0).to(torch.float) * daf2\n",
        "dw2 = af1.T @ dz2\n",
        "db2 = dz2.sum(0)\n",
        "daf1 = dz2 @ w2.T\n",
        "dz1 = z1.clone()\n",
        "dz1 = torch.where(dz1 > 0, 1, 0).to(torch.float) * daf1\n",
        "\n",
        "# Backward Atomic CNN Layer\n",
        "dflatten = dz1 @ w1.T\n",
        "dpool2 = torch.ones_like(pool2) * dflatten.view(pool2.shape)\n",
        "dconv2 = pool_back(conv2, pool_kernel, dpool2, stride=2)\n",
        "dfilter2 = conv_back(pool1.clone(), dconv2, stride=1)\n",
        "dpool1 = conv(dconv2 ,rotate_180(filter2), padding=2, stride=1)\n",
        "dconv1 = pool_back(conv1, pool_kernel, dpool1, stride=2)\n",
        "dfilter1 = conv_back(x_train, dconv1, stride=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "lbBkqfpXPntx",
        "collapsed": true
      },
      "execution_count": 1804,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #utitlity function to check manually calculated gradients with that of pytorch autograd\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "QyaScbmnu8Zp"
      },
      "execution_count": 1805,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing gradients for 2 layers"
      ],
      "metadata": {
        "id": "3-jihAeXzQ_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmp('filter1', dfilter1, filter1)\n",
        "cmp('conv1', dconv1, conv1)\n",
        "cmp('pool1', dpool1, pool1)\n",
        "cmp('filter2', dfilter2, filter2)\n",
        "cmp('conv2', dconv2, conv2)\n",
        "cmp('pool2', dpool2, pool2)\n",
        "cmp('flatten', dflatten, flatten)\n",
        "cmp('z1', dz1, z1)\n",
        "cmp('af1', daf1, af1)\n",
        "cmp('z2', dz2, z2)\n",
        "cmp('af2', daf2, af2)\n",
        "cmp('z3', dz3, z3)\n",
        "cmp('z_max', dz_max, z_max)\n",
        "cmp('norm_z', dnorm_z, norm_z)\n",
        "cmp('exp_norm_z', dexp_norm_z, exp_norm_z)\n",
        "cmp('z_sum', dz_sum, z_sum)\n",
        "cmp('z_sum_inv', dz_sum_inv, z_sum_inv)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('logprobs', dlogprobs, logprobs)\n"
      ],
      "metadata": {
        "id": "eN8U0yMbaXz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832f5ef5-1623-4bd8-b869-be7eb8d79ea4"
      },
      "execution_count": 1806,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter1         | exact: False | approximate: True  | maxdiff: 2.2737367544323206e-13\n",
            "conv1           | exact: False | approximate: True  | maxdiff: 5.684341886080802e-14\n",
            "pool1           | exact: False | approximate: True  | maxdiff: 5.684341886080802e-14\n",
            "filter2         | exact: False | approximate: True  | maxdiff: 1.7053025658242404e-13\n",
            "conv2           | exact: False | approximate: True  | maxdiff: 2.2737367544323206e-12\n",
            "pool2           | exact: False | approximate: True  | maxdiff: 2.2737367544323206e-12\n",
            "flatten         | exact: False | approximate: True  | maxdiff: 2.2737367544323206e-12\n",
            "z1              | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "af1             | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
            "z2              | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "af2             | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "z3              | exact: False | approximate: True  | maxdiff: 1.862645149230957e-08\n",
            "z_max           | exact: False | approximate: False | maxdiff: 2.2351741790771484e-08\n",
            "norm_z          | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "exp_norm_z      | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "z_sum           | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "z_sum_inv       | exact: False | approximate: True  | maxdiff: 2.384185791015625e-07\n",
            "probs           | exact: False | approximate: True  | maxdiff: 2.384185791015625e-07\n",
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRS_uUnqbXTu"
      },
      "execution_count": 1812,
      "outputs": []
    }
  ]
}